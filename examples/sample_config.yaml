# Sample Configuration File for Jeopardy Benchmarking System
# Copy this file to config/default.yaml and modify as needed

# Application settings
name: "Jeopardy Benchmark System"
version: "1.0.0"
environment: "development"
debug: false

# Database configuration
database:
  url: "sqlite:///data/benchmarks.db"
  echo: false
  pool_size: 5
  backup:
    enabled: true
    rotation: 5
    path: "./backups"

# OpenRouter API configuration
openrouter:
  base_url: "https://openrouter.ai/api/v1"
  timeout: 30
  max_retries: 3
  rate_limit:
    requests_per_minute: 60
    backoff_factor: 2.0
    max_backoff: 60.0
  default_model: "openai/gpt-3.5-turbo"
  streaming: false
  headers:
    referer: "https://alex-trebench.local"
    title: "alex-treBENCH Benchmarking System"

# Cache configuration
cache:
  enabled: true
  ttl: 3600
  max_size: 1000

# Benchmark configuration
benchmark:
  modes:
    quick:
      sample_size: 50
      categories: 5
      timeout: 30
      max_retries: 2
    standard:
      sample_size: 200
      categories: 10
      timeout: 60
      max_retries: 3
    comprehensive:
      sample_size: 1000
      categories: "all"
      timeout: 120
      max_retries: 3
  grading:
    default_mode: "lenient"
    confidence_threshold: 0.7
    partial_credit: true
    jeopardy_format_required: false
  parallel:
    max_concurrent_models: 3
    max_concurrent_requests: 10
    rate_limit_per_minute: 60
  default_sample_size: 200
  confidence_level: 0.95
  margin_of_error: 0.05
  answer_similarity_threshold: 0.7
  max_concurrent_requests: 5

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/benchmark.log"
  max_size: "10MB"
  backup_count: 5

# Kaggle dataset configuration
kaggle:
  dataset: "aravindram11/jeopardy-dataset-updated"
  cache_dir: "data/raw"

# Model defaults
models:
  defaults:
    temperature: 0.1
    max_tokens: 150
    top_p: 0.9
  overrides:
    openai/gpt-4:
      temperature: 0.3
      max_tokens: 200
    anthropic/claude-3-sonnet:
      temperature: 0.2
      max_tokens: 180

# Reporting configuration
reporting:
  default_format: "terminal"
  include_metadata: true
  export_path: "./reports"
  visualization: true