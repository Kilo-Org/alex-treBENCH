# OpenAI Models Configuration
# Specific settings for OpenAI GPT models

models:
  defaults:
    temperature: 0.7
    max_tokens: 150
    top_p: 0.9
    frequency_penalty: 0.0
    presence_penalty: 0.0

  overrides:
    "openai/gpt-4":
      temperature: 0.5
      max_tokens: 200
      top_p: 0.95
      context_window: 8192
      pricing:
        input: 0.03
        output: 0.06

    "openai/gpt-4-turbo":
      temperature: 0.6
      max_tokens: 250
      top_p: 0.95
      context_window: 128000
      pricing:
        input: 0.01
        output: 0.03

    "openai/gpt-3.5-turbo":
      temperature: 0.7
      max_tokens: 150
      top_p: 0.9
      context_window: 16385
      pricing:
        input: 0.0015
        output: 0.002

    "openai/gpt-3.5-turbo-16k":
      temperature: 0.7
      max_tokens: 200
      top_p: 0.9
      context_window: 16385
      pricing:
        input: 0.003
        output: 0.004

benchmark:
  modes:
    quick:
      sample_size: 50
      timeout: 25
    standard:
      sample_size: 150
      timeout: 45
    comprehensive:
      sample_size: 500
      timeout: 90

rate_limits:
  requests_per_minute: 60
  burst_limit: 10
  backoff_factor: 2.0

features:
  supports_streaming: true
  supports_functions: true
  supports_vision: false